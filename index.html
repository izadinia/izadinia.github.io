<html>

<head>
    <title>Hamid Izadinia</title>
    <link rel="stylesheet" href="mystyle.css" type="text/css" media="screen" title="no title" charset="utf-8" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-55937368-1', 'auto');
        ga('send', 'pageview');
    </script>
</head>

<body>

<div id="centered-page">

<div id="nav" class="navbar navbar-inverse navbar-static-top" style="margin-top:0.35em">
    <div class="navbar-inner">
        <div class="container">
            &nbsp;<a class="brand" href=".">Hamid Izadinia</a>
        </div>
    </div>
</div>

<div id="news">
    <div class="subsectionTitle">
        <a href="https://twitter.com/izadinia?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @izadinia</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>        
    </div>
    <div class="subsectionTitle">
        <div class="icon right-info-big">
            <a href="http://scholar.google.com/citations?user=uDuLNHkAAAAJ&hl=en&sortby=pubdate">Google citations</a>
            <!--a href="http://www.informatik.uni-trier.de/~ley/pers/hd/i/Izadinia:Hamid">DBLP</a--><br/>

        </div>
    </div>

    <div class=subsectionTitle>
        contact
    </div>
    <div class='icon right-info'>
        izadinia AT cs.washington.edu<br />
    </div>

    <div class=subsectionTitle>
        address
    </div>
    <div class="icon right-info">
        Computer Science & Engr.</br>
        AC 101 Paul G Allen Center</br>
        185 Stevens Way</br>
        Seattle, WA 98195-2350
    </div>
    <!--hr class=white-->

    <!--div class=subsectionTitle>
        news
    </div>


    <hr class="white">
    <div class=right-info>
        <div class=subsectionTitle>
        </div>
    </div-->
</div>

<div id="overview">
    <span style="float:left; float:top; padding: 5px 8px 4px 0px">
	<img src="images/Hamid_Izadinia.jpg" style="display: inline-block; float:left; float: top" width="210" />
	<p></p>        
	<br />
        <br />
        <br />
    </span>
    <div class="chunk_bio" style='margin-top:.5em;padding-top:10px;font-size:1.4em;font-weight:300'>

        I'm a PhD candidate in Computer Science at University of Washington, advised by Prof. <a href="http://homes.cs.washington.edu/~seitz/">Steve Seitz</a>. I'm also part of the Graphics-Vision Lab (<a href="http://grail.cs.washington.edu/people/">GRAIL</a>) at UW.
        <br />
        <br />
        My research interest include learning 3D, scene geometry reconstruction and semantic understanding as well as deep reinforcement learning.
        <br />
        <br />
        <br />

     </div>
</div>
<hr class=white>


<div id="main">
<div id="research">

<center>    
    <div class="sectionTitle" style="margin-top:.5em" >
        Work Experience
    </div>

    <br />

    <table class="table papers" id="papers" style="margin-top:0;">
        <tr>
            <td align="center">
                <a href="https://research.fb.com/category/augmented-reality-virtual-reality/">
                    <img class="logothumb" src="images/FRL_Facebook_Reality_Labs.png"/>
                </a>
            </td>
            <td><div class="paperTitle">
                Facebook Reality Labs (FRL)<br/>Student Researcher<br/>Redmond, WA</br>Fall 2017-Winter 2019
            </div>
            </td>
            <td align="center">
                <a href="https://www.oculus.com/research/">
                    <img class="logothumb" src="images/Oculus_logo.jpg"/>
                </a>
            </td>
            <td><div class="paperTitle">
                Research Intern, Oculus Research<br/>San Francisco, CA<br/>Summer 2017
            </div>
            </td>

            <td>
            </td>
	    </tr>
        <tr>
            <td align="center">
                <a href="https://www.flickr.com/">
                    <img class="logothumb" src="images/flickr_logo_rc.jpg"/>
                </a>
            </td>
            <td><div class="paperTitle">
                Research Intern, Flickr<br/>San Francisco, CA<br/>Summer 2016
            </div>
            </td>
            <td align="center">
                <a href="http://www.adobe.com/technology.html">
                    <img class="logothumb" src="images/adobe_logo.jpg"/>
                </a>
            </td>
            <td><div class="paperTitle">
                Research Intern, Adobe Research</br>(Creative Technologies Lab)<br/>San Francisco, CA<br/>Summer 2014
            </div>
            </td>        

       
        </tr>
        <tr>
            <td align="center">
                <a href="https://la.disneyresearch.com">
                    <img class="logothumb" src="images/Disney_Research_Logo.jpg"/>
                </a>
            </td>
            <td><div class="paperTitle">
                Research Intern, Disney Research<br/>Pittsburgh, PA<br/>Summer 2013
            </div>
            </td>
            <td align="center">
                <a href="http://ri.cmu.edu/">
                    <img class="logothumb" src="images/RI_medium_logo.jpg"/>
                </a>
            </td>
            <td><div class="paperTitle">
                Visiting scholar, Robotics Institute</br>Carnegie Mellon University<br/>Pittsburgh, PA<br/>Summer 2012
            </div>
            </td>
            <td>
            </td>
            <td>
            </td>
            <td>
            </td>
        </tr>
    </table>
</center>

<br />

<hr class=white>

<center>
    <div class="sectionTitle" style="margin-top:1em" >
        selected publications (<a href="http://scholar.google.com/citations?user=uDuLNHkAAAAJ&hl=en&sortby=pubdate">All publications</a>)
    </div>
</center>

<table class="table papers" id="papers" style="margin-top:0;">
    <br />

    <tr style="margin-bottom:1em;">
        <td>
            <a href="https://izadinia.github.io/RMPC">
                <img class="paperthumb" src="images/rmpc_teaser.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="https://izadinia.github.io/RMPC">Nonprehensile Riemannian Motion Predictive Control</a>
        </div>
            <span class="authors"> Hamid Izadinia, Byron Boots, Steven M. Seitz</span><br/>
            <cite>International Symposium on Experimental Robotics (<a href="http://iser2020.org">ISER 2020</a>). </cite><br/>
            <span class='keyword'><strong>Keywords:</strong> Riemannian Motion Policy (RMP), Nonprehensile manipulation, Model Predictive Control (MPC), Closed-Loop Control, Real-to-Sim reward analysis, RMPflow, real RC-car robot, fully automatic object-level scene recomposition, point cloud input, YCB dataset.</span>
            <br/>
            <a href="https://izadinia.github.io/RMPC/files/RMPC_ISER2020.pdf">pdf</a>&nbsp;&middot;&nbsp;<a href="https://arxiv.org/abs/2111.07986">arXiv</a>&nbsp;&middot;&nbsp;<a href="https://izadinia.github.io/RMPC">project page</a><img src="images/new1.png" height="20" width="60">
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr style="margin-bottom:1em;">
        <td>
            <a href="https://izadinia.github.io/LICP">
                <img class="paperthumb" src="images/licp_recomposition_teaser.gif"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="https://izadinia.github.io/LICP">Scene Recomposition by Learning-based ICP</a>
        </div>
            <span class="authors"> Hamid Izadinia, Steven M. Seitz</span><br/>
            <cite>CVPR 2020. </cite><br/>
            <span class='keyword'>A novel learning-based ICP and fully automatic Scene Recomposition that utilizes thousands of 3D CAD models to align 3D CAD to depth scan by Deep RL.</span><br/>
            <span class='keyword'><strong>Keywords:</strong> 3D scene recomposition, 3D scene reconstruction, Deep reinforcement learning (Deep RL), Learning-based ICP (LICP), 3D geometry learning, 3D CAD models, 3D shapes, Room layout estimation, 3D geometry deep network, Iterative Closest Point, 3D geometry network, noisy scan.</span>
            <br/>
            <a href="https://izadinia.github.io/LICP/files/LICP_CVPR2020.pdf">pdf</a>&nbsp;&middot;&nbsp;<a href="https://arxiv.org/abs/1812.05583">arXiv</a>&nbsp;&middot;&nbsp;<a href="https://izadinia.github.io/LICP">project page</a><img src="images/new1.png" height="20" width="60">
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr style="margin-bottom:1em;">
        <td>
            <a href="https://izadinia.github.io/VISER">
                <img class="paperthumb" src="images/viser_teaser2.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="https://izadinia.github.io/VISER">VISER: Visual Self-Regularization</a>
        </div>
            <span class="authors"> Hamid Izadinia, Pierre Garrigues</span><br/>
            <cite>CVPR 2020 - VL3. </cite><br/>
            <span class='keyword'>A novel method to harness real adversarial examples from unlabeled images as a source of regularization data for learning robust visual representation.</span><br/>
            <span class='keyword'><strong>Keywords:</strong> Visual self regularizers, approximate nearest neighbor, real adversarial example, adversarial regularization, regularization for training ConvNets, object-in-context retrieval and visual localization, semi-supervised and weakly-supervised deep learning, fully convolutional deep neural network, t-SNE embedding map, MS COCO and Visual Genome and YFCC100M dataset.</span>
            <br/>
            <a href="https://arxiv.org/pdf/1802.02568.pdf">pdf</a>&nbsp;&middot;&nbsp;<a href="https://www.youtube.com/watch?v=labbc_UEH5k">video</a>&nbsp;&middot;&nbsp;<a href="https://izadinia.github.io/VISER">project page</a><img src="images/new1.png" height="20" width="60">
            <br/>
        </td>
    </tr>


    <tr style="margin-bottom:1em;">
        <td>
            <a href="https://izadinia.github.io/IM2CAD">
                <img class="paperthumb" src="images/im2cad_teaser.gif"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="https://izadinia.github.io/IM2CAD">IM2CAD</a>
        </div>
            <span class="authors"> Hamid Izadinia, Qi Shan, Steven M. Seitz</span><br/>
            <cite>CVPR 2017. </cite><strong>(spotlight)</strong><br/>
            <span class='keyword'><strong>Keywords:</strong> 3D scene reconstruction, convolutional neural network, reconstruction-recognition, scene optimization via render-and-match, single view geometry, room layout estimation, 3D CAD models.</span>
            <br/>
            <a href="https://izadinia.github.io/IM2CAD/files/im2cad_CVPR17.pdf">pdf</a>&nbsp;&middot;&nbsp;<a href="https://arxiv.org/abs/1608.05137">arXiv</a>&nbsp;&middot;&nbsp;<a href="https://izadinia.github.io/IM2CAD">project page</a>
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr style="margin-bottom:1em;">
        <td>
            <a href="https://arxiv.org/abs/1612.01922">
                <img class="paperthumb" src="images/tag_prediction_flickr_teaser.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="https://arxiv.org/abs/1612.01922">Tag Prediction at Flickr: a View from the Darkroom</a>
        </div>
            <span class="authors">Kofi Boakye, Sachin Farfade, Hamid Izadinia, Yannis Kalantidis, Pierre Garrigues</span><br/>
            <cite>NeurIPS 2016 - Large Scale Computer Vision systems Workshop. </cite><a href="https://arxiv.org/abs/1612.01922">(Best paper award)</a><br/>
            <span class='keyword'>Keywords: photo tagging, interpretable representation, deep convolutional neural networks, developing large-scale photo tagging system, lightweight and high-performance models, training noisy data.</span>
            <br/>
            <a href="https://arxiv.org/abs/1612.01922">pdf</a>
            <br/>
        </td>
    </tr>

    <tr>
        <td>
            <a href="http://arxiv.org/pdf/1509.08075v1.pdf">
                <img class="paperthumb" src="images/VisualEntailment_teaser.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="http://arxiv.org/pdf/1509.08075v1.pdf">Segment-Phrase Table for Semantic Segmentation, Visual Entailment and Paraphrasing</a>
        </div>
            <span class="authors">H. Izadinia, F. Sadeghi, S.K. Divvala, Y. Choi, A. Farhadi</span><br/>
            <cite>ICCV 2015. </cite><strong>(oral)</strong><br/>
            <span class='keyword'>Keywords: visual entailment, visual paraphrasing, semantic segmentation, large-scale recognition.</span>
            <br/>
            <a href="http://arxiv.org/pdf/1509.08075v1.pdf">pdf</a>
            <!--img src="images/new1.png" height="20" width="60"-->
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr>
        <td>
            <a href="http://deep-tagging.cs.washington.edu">
                <img class="paperthumb" src="images/tagging_teaser.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="http://deep-tagging.cs.washington.edu">Deep Classifiers from Image Tags in the Wild</a>
        </div>
            <span class="authors">H. Izadinia, B. Russell, A. Farhadi, M. Hoffman, A. Hertzmann</span><br/>
            <cite>Multimedia COMMONS, ACM Multimedia, 2015.</cite><br/>
            <span class='keyword'>Keywords: deep learning, convolutional neural network, large-scale recognition, photo tagging, image classification, image retrieval, robust classification, deep tagging, YFCC100M (as noisy labeled dataset).</span>
            <br/>
            <a href="files/DeepTagging-mmcommons.pdf">pdf</a>
            &nbsp;&middot;&nbsp;<a target="_blank" href="http://deep-tagging.cs.washington.edu">Deep-Tagging demo<!--img src="images/new1.png" height="20" width="60"-->  
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr>
        <td>
            <a href="http://grail.cs.washington.edu/wp-content/uploads/2015/08/izadinia2014isc.pdf">
                <img class="paperthumb" src="images/scene_context_teaser2.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="http://grail.cs.washington.edu/wp-content/uploads/2015/08/izadinia2014isc.pdf">Incorporating Scene Context and Object Layout into Appearance Modeling</a>
        </div>
            <span class="authors"> H. Izadinia*, F. Sadeghi*, A. Farhadi</span><br/>
            <cite>CVPR, 2014.</cite><br/>
            <span class='keyword'>Keywords: scene understanding, large-scale recognition, object layout inference, structured SVM, black-box test, scene context.</span>
            <br/>
            <a href="http://grail.cs.washington.edu/wp-content/uploads/2015/08/izadinia2014isc.pdf">pdf</a>
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr>
        <td>
            <a href="files/1412.6079v1.pdf">
                <img class="paperthumb" src="images/decoding_encoding_teaser.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="files/1412.6079v1.pdf">Decoding the Text Encoding</a>
        </div>
            <span class="authors"> F. Sadeghi, H. Izadinia</span><br/>
            <cite>preprint arXiv:1412.6079, December 2014.</cite><br/>
            <span class='keyword'>Keywords: diagram understanding, visualization redesign, text visualization, computer vision, word cloud.</span>
            <br/>
            <a href="files/1412.6079v1.pdf">pdf</a>
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr>
        <td>
            <a href="files/LatentEvent-ECCV12.pdf">
                <img class="paperthumb" src="images/event_teaser.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="files/LatentEvent-ECCV12.pdf">Recognizing Complex Events using Large Margin Joint Low-level Event Model</a>
        </div>
            <span class="authors"> H. Izadinia, M. Shah</span><br/>
            <cite>ECCV, 2012.</cite><br/>
            <span class='keyword'>Keywords: complex event recognition, action recognition, structured learning, latent SVM.</span>
            <br/>
            <a href="files/LatentEvent-ECCV12.pdf">pdf</a>
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr>
        <td>
            <a href="files/MPMPT-ECCV12.pdf">
                <img class="paperthumb" src="images/mp2t_teaser.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="files/MPMPT-ECCV12.pdf">(MP)2T: Multiple People Multiple Parts Tracker</a>
        </div>
            <span class="authors"> H. Izadinia, I. Saleemi, W. Li, M. Shah</span><br/>
            <cite>ECCV, 2012.</cite><br/>
            <span class='keyword'>Keywords: multi-target, tracking, pedestrians, humans, body part tracking, network flow optimization, k-shortest paths.</span>
            <br/>
            <a href="files/MPMPT-ECCV12.pdf">pdf</a>
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr>
        <td>
            <a href="files/TMM_audio_video_correlation.pdf">
                <img class="paperthumb" src="images/audio_video_teaser.jpg" height="170"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="files/TMM_audio_video_correlation.pdf">Multimodal Analysis for Identification and Segmentation of Moving-Sounding Objects</a>
        </div>
            <span class="authors"> H. Izadinia, I. Saleemi, M. Shah</span><br/>
            <cite>IEEE TRANSACTIONS ON MULTIMEDIA, 2013.</cite><br/>
            <span class='keyword'>Keywords: audio-visual analysis, canonical correlation analysis, video segmentation, audio-visual synchronization.</span>
            <br/>
            <a href="files/TMM_audio_video_correlation.pdf">pdf</a>
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

    <tr>
        <td>
            <a href="files/PID2616061.pdf">
                <img class="paperthumb" src="images/WACV13_teaser.jpg"/>
            </a>
        </td>
        <td><div class="paperTitle">
            <a href="files/PID2616061.pdf">Multi-Pose Multi-Target Tracking for Human Activity Understanding</a>
        </div>
            <span class="authors"> H. Izadinia, V. Ramakrishna, K. Kitani, D. Huber</span><br/>
            <cite>WACV 2013.</cite><br/>
            <span class='keyword'>Keywords: human pose estimation, multi-target tracking, action recognition.</span>
            <br/>
            <a href="files/PID2616061.pdf">pdf</a>
            <!--a href="">bibtex</a-->
            <br/>
        </td>
    </tr>

</table>

<br />

<hr class=white>

<center>
    <div class="sectionTitle" style="margin-top:1em" >
        Teaching GTA
    </div>
</center>

<table class="table papers" id="papers" style="margin-top:0;">

    <tr>
        <td>
            <div class="paperTitle">
            <a href="https://courses.cs.washington.edu/courses/cse473/">Introduction to Artificial Intelligence</a>
            </div>
            <div class="paperTitle">
            <a href="https://courses.cs.washington.edu/courses/cse473/18au/">CSE 473 (Fall 2018)</a>
            </div>
            <div class="paperTitle">
            <a href="https://courses.cs.washington.edu/courses/cse415/19wi/staff.html">CSE 415 (Winter 2019)</a>
            </div>

        <td>
            <br/>
            <span class='keyword'>Reinforcement Learning (RL), Q-Learning,</span>
            <br/>
            <span class='keyword'>Value Iteration, Markov Decision Process (MDP),</span>
            <br/>
            <span class='keyword'>CSP, Search, HMM, Bayesian Net, Perceptron.</span>
            <br/>
            <a href="https://courses.cs.washington.edu/courses/cse473/18au/"></a>
            <br/>
        </td>
        </td>
        <td>
        </td>
    </tr>
    <tr>
        <td>
            <a href="https://courses.cs.washington.edu/courses/cse473/18au/">
                <img class="paperthumb" src="images/pacman_Expectimax.gif"/>
            </a>
        </td>
        <td>
            <a href="https://courses.cs.washington.edu/courses/cse473/18au/">
                <img class="paperthumb" src="images/QValueUpdate_Q-Learning_epsilonGreedy.gif"/>
            </a>
        </td>
        <td>
            <a href="https://courses.cs.washington.edu/courses/cse473/18au/">
                <img class="paperthumb" src="images/pacman_Q-Learning.gif"/>
            </a>
        </td>
    </tr>

</table>
<hr class=white>

<div class="sectionTitle" style="margin-top:1.5em" >
    Misc
</div>

<table class="table papers" id="papers" style="margin-top:0;">
    <tr>
        <td>
            <div>
                Find the slides of our computer vision seminar class <a href="https://courses.cs.washington.edu/courses/cse590v/14au">CSE590v (Autumn 2014)</a>
            </div>
        </td>
    </tr>
    <tr>
        <td>
                <br/>
                <br/>
                <br/>
        </td>
    </tr>

</table>

</div>
</div>
</div>

</div>
</body>
</html>
